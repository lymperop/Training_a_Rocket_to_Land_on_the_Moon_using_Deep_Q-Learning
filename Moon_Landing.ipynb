{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "363f6880",
   "metadata": {},
   "source": [
    "# 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b9abb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System modules\n",
    "import os\n",
    "import shutil\n",
    "import joblib\n",
    "\n",
    "\n",
    "# Scientific modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Environment\n",
    "import gym\n",
    "\n",
    "# Base agent\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db67203",
   "metadata": {},
   "source": [
    "- *os* and *shutil* are modules for interacting with the operating system and file system\n",
    "- *joblib* module is used here to save agent objects to files\n",
    "- *numpy* and *matplotlib.pylab* are fundamental packages for scientific computing and plotting graphs\n",
    "- *tqdm* package is used to display progress while running experiments\n",
    "- *gym* is a standard API for reinforcement learning, and a diverse collection of reference environments\n",
    "- *deepcopy* packages is used to create copies of mutable objects for agent training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9da946a",
   "metadata": {},
   "source": [
    "# 2. Define Agent\n",
    "Create abstract agent class to implement the agent for an RL-Glue environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1bf59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"An abstract class that specifies the Agent API for RL-Glue-py.\n",
    "\"\"\"\n",
    "class BaseAgent(ABC):\n",
    "    \"\"\"Implements the agent for an RL-Glue environment.\n",
    "    Note:\n",
    "        agent_init, agent_start, agent_step, agent_end, agent_cleanup, and\n",
    "        agent_message are required methods.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def agent_init(self, agent_info= {}):\n",
    "        \"\"\"Setup for the agent called when the experiment first starts.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def agent_start(self, observation):\n",
    "        \"\"\"The first method called when the experiment starts, called after\n",
    "        the environment starts.\n",
    "        Args:\n",
    "            observation (Numpy array): the state observation from the environment's evn_start function.\n",
    "        Returns:\n",
    "            The first action the agent takes.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def agent_step(self, reward, observation):\n",
    "        \"\"\"A step taken by the agent.\n",
    "        Args:\n",
    "            reward (float): the reward received for taking the last action taken\n",
    "            observation (Numpy array): the state observation from the\n",
    "                environment's step based, where the agent ended up after the\n",
    "                last step\n",
    "        Returns:\n",
    "            The action the agent is taking.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def agent_end(self, reward):\n",
    "        \"\"\"Run when the agent terminates.\n",
    "        Args:\n",
    "            reward (float): the reward the agent received for entering the terminal state.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def agent_cleanup(self):\n",
    "        \"\"\"Cleanup done after the agent ends.\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def agent_message(self, message):\n",
    "        \"\"\"A function used to pass information from the agent to the experiment.\n",
    "        Args:\n",
    "            message: The message passed to the agent.\n",
    "        Returns:\n",
    "            The response (or answer) to the message.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4083943c",
   "metadata": {},
   "source": [
    "Create rocket agent to be trained. The agent uses Expected Sarsa to train a Deep Neural Network with a replay/experience buffer to store trajectories of experience when executing the policy in the lunar environment. During training, the replay buffer is queried for a sample of the trajectories to \"replay\" the agent's experience for learning. The replayed buffer can be queried several times in one agent step, the number of which is defined by \"self.num_replay\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f97dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplay_Agent(BaseAgent):\n",
    "    def __init__(self):\n",
    "        self.name = \"expected_sarsa_agent\"\n",
    "\n",
    "    def agent_init(self, agent_config):\n",
    "        \"\"\"Setup for the agent called when the experiment first starts.\n",
    "\n",
    "        Set parameters needed to setup the agent.\n",
    "\n",
    "        Assume agent_config dict contains:\n",
    "        {\n",
    "            network_config: dictionary,\n",
    "            optimizer_config: dictionary,\n",
    "            replay_buffer_size: integer,\n",
    "            minibatch_sz: integer,\n",
    "            num_replay_updates_per_step: float\n",
    "            discount_factor: float,\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.name = \"expected_sarsa_agent_{}\".format(agent_config['agent_name'])\n",
    "        self.replay_buffer = ReplayBuffer(agent_config['replay_buffer_size'],\n",
    "                                          agent_config['minibatch_sz'], agent_config.get(\"seed\"))\n",
    "        self.network = ActionValueNetwork(agent_config['network_config'])\n",
    "        self.optimizer = Adam(self.network.layer_sizes, agent_config[\"optimizer_config\"])\n",
    "        self.num_actions = agent_config['network_config']['num_actions']\n",
    "        self.num_replay = agent_config['num_replay_updates_per_step']\n",
    "        self.discount = agent_config['gamma']\n",
    "        self.tau = agent_config['tau']\n",
    "\n",
    "        self.rand_generator = np.random.RandomState(agent_config.get(\"seed\"))\n",
    "\n",
    "        self.last_state = None\n",
    "        self.last_action = None\n",
    "\n",
    "        self.sum_rewards = 0\n",
    "        self.episode_steps = 0\n",
    "\n",
    "    def policy(self, state):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state (Numpy array): the state.\n",
    "        Returns:\n",
    "            the action.\n",
    "        \"\"\"\n",
    "        action_values = self.network.get_action_values(state)\n",
    "        probs_batch = softmax(action_values, self.tau)\n",
    "        action = self.rand_generator.choice(self.num_actions, p=probs_batch.squeeze())\n",
    "        return action\n",
    "\n",
    "    def agent_start(self, state):\n",
    "        \"\"\"The first method called when the experiment starts, called after\n",
    "        the environment starts.\n",
    "        Args:\n",
    "            state (Numpy array): the state from the\n",
    "                environment's evn_start function.\n",
    "        Returns:\n",
    "            The first action the agent takes.\n",
    "        \"\"\"\n",
    "        self.sum_rewards = 0\n",
    "        self.episode_steps = 0\n",
    "        self.last_state = np.array([state])\n",
    "        self.last_action = self.policy(self.last_state)\n",
    "        return self.last_action\n",
    "\n",
    "    def agent_step(self, reward, state):\n",
    "        \"\"\"A step taken by the agent: Action selection, replay-buffer update, \n",
    "        weights update using optimize_network, and update last_state and last_action\n",
    "        Args:\n",
    "            reward (float): the reward received for taking the last action taken\n",
    "            state (Numpy array): the state from the\n",
    "                environment's step based, where the agent ended up after the\n",
    "                last step\n",
    "        Returns:\n",
    "            The action the agent is taking.\n",
    "        \"\"\"\n",
    "\n",
    "        self.sum_rewards += reward\n",
    "        self.episode_steps += 1\n",
    "\n",
    "        # Make state an array of shape (1, state_dim) to add a batch dimension and\n",
    "        # to later match the get_action_values() and get_TD_update() functions\n",
    "        state = np.array([state])\n",
    "\n",
    "        # Select action\n",
    "        action = self.policy(state)\n",
    "\n",
    "        # Append new experience to replay buffer\n",
    "        self.replay_buffer.append(self.last_state, self.last_action, reward, 0, state)\n",
    "\n",
    "        # Perform replay steps:\n",
    "        if self.replay_buffer.size() > self.replay_buffer.minibatch_size:\n",
    "            current_q = deepcopy(self.network)\n",
    "            for _ in range(self.num_replay):\n",
    "                # Get sample experiences from the replay buffer\n",
    "                experiences = self.replay_buffer.sample()\n",
    "\n",
    "                # Call optimize_network to update the weights of the network \n",
    "                optimize_network(experiences, self.discount, self.optimizer, self.network, current_q, self.tau)\n",
    "\n",
    "        # Update the last state and last action.\n",
    "        self.last_state = state\n",
    "        self.last_action = action\n",
    "\n",
    "        return action\n",
    "\n",
    "    def agent_end(self, reward):\n",
    "        \"\"\"Run when the agent terminates.\n",
    "        Args:\n",
    "            reward (float): the reward the agent received for entering the\n",
    "                terminal state.\n",
    "        \"\"\"\n",
    "        self.sum_rewards += reward\n",
    "        self.episode_steps += 1\n",
    "\n",
    "        # Set terminal state to an array of zeros\n",
    "        state = np.zeros_like(self.last_state)\n",
    "\n",
    "        # Append new experience to replay buffer\n",
    "        self.replay_buffer.append(self.last_state, self.last_action, reward, 1, state)\n",
    "\n",
    "        # Perform replay steps:\n",
    "        if self.replay_buffer.size() > self.replay_buffer.minibatch_size:\n",
    "            current_q = deepcopy(self.network)\n",
    "            for _ in range(self.num_replay):\n",
    "                # Get sample experiences from the replay buffer\n",
    "                experiences = self.replay_buffer.sample()\n",
    "\n",
    "                # Call optimize_network to update the weights of the network\n",
    "                optimize_network(experiences, self.discount, self.optimizer, self.network, current_q, self.tau)\n",
    "\n",
    "    def agent_cleanup(self):\n",
    "        \"\"\"Cleanup done after the agent ends.\"\"\"\n",
    "        \n",
    "    def agent_message(self, message):\n",
    "        if message == \"get_sum_reward\":\n",
    "            return self.sum_rewards\n",
    "        else:\n",
    "            raise Exception(\"Unrecognized Message!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8f1a6",
   "metadata": {},
   "source": [
    "## Replay/Experience Buffer\n",
    "The experience buffer store trajectories of experience when executing the policy in the lunar environment. For each step, the buffer stores the current state and action, the reward and next state, and whether the agent reached a terminal state. During training, the replay buffer is queried for a sample of the trajectories to \"replay\" the agent's experience for learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254cdcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, size, minibatch_size, seed):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            size (integer): The size of the replay buffer.\n",
    "            minibatch_size (integer): The sample size.\n",
    "            seed (integer): The seed for the random number generator.\n",
    "        \"\"\"\n",
    "        self.buffer = []\n",
    "        self.minibatch_size = minibatch_size\n",
    "        self.rand_generator = np.random.RandomState(seed)\n",
    "        self.max_size = size\n",
    "\n",
    "    def append(self, state, action, reward, terminal, next_state):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            state (Numpy array): The state.\n",
    "            action (integer): The action.\n",
    "            reward (float): The reward.\n",
    "            terminal (integer): 1 if the next state is a terminal state and 0 otherwise.\n",
    "            next_state (Numpy array): The next state.\n",
    "        \"\"\"\n",
    "        if len(self.buffer) == self.max_size:\n",
    "            del self.buffer[0]\n",
    "        self.buffer.append([state, action, reward, terminal, next_state])\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            A list of transition tuples including state, action, reward, terinal, and next_state\n",
    "        \"\"\"\n",
    "        idxs = self.rand_generator.choice(np.arange(len(self.buffer)), size=self.minibatch_size)\n",
    "        return [self.buffer[idx] for idx in idxs]\n",
    "\n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219459f2",
   "metadata": {},
   "source": [
    "## Function approximator: Neural Network with Adam optimizer using Expected SARSA\n",
    "The agent learns by training a neural network, which is used as a function approximator of the action-value function in the control problem. The output includes as many units as the number of actions. The weights of the action-value network are updated using the Adam algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4f43c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionValueNetwork:\n",
    "\n",
    "    def __init__(self, network_config):\n",
    "        self.state_dim = network_config.get(\"state_dim\")\n",
    "        self.num_hidden_units = network_config.get(\"num_hidden_units\")\n",
    "        self.num_actions = network_config.get(\"num_actions\")\n",
    "\n",
    "        self.rand_generator = np.random.RandomState(network_config.get(\"seed\"))\n",
    "\n",
    "        self.layer_sizes = [self.state_dim, self.num_hidden_units, self.num_actions]\n",
    "\n",
    "        # Initialize the weights of the neural network\n",
    "        # self.weights is an array of dictionaries with each dictionary corresponding to\n",
    "        # the weights from one layer to the next. Each dictionary includes W and b\n",
    "        self.weights = [dict() for i in range(0, len(self.layer_sizes) - 1)]\n",
    "        for i in range(0, len(self.layer_sizes) - 1):\n",
    "            self.weights[i]['W'] = self.init_saxe(self.layer_sizes[i], self.layer_sizes[i + 1])\n",
    "            self.weights[i]['b'] = np.zeros((1, self.layer_sizes[i + 1]))\n",
    "\n",
    "    def get_action_values(self, s):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            s (Numpy array): The state.\n",
    "        Returns:\n",
    "            The action-values (Numpy array) calculated using the network's weights.\n",
    "        \"\"\"\n",
    "\n",
    "        W0, b0 = self.weights[0]['W'], self.weights[0]['b']\n",
    "        psi = np.dot(s, W0) + b0\n",
    "        x = np.maximum(psi, 0)\n",
    "\n",
    "        W1, b1 = self.weights[1]['W'], self.weights[1]['b']\n",
    "        q_vals = np.dot(x, W1) + b1\n",
    "\n",
    "        return q_vals\n",
    "\n",
    "\n",
    "    def get_TD_update(self, s, delta_mat):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            s (Numpy array): The state.\n",
    "            delta_mat (Numpy array): A 2D array of shape (batch_size, num_actions). Each row of delta_mat\n",
    "            correspond to one state in the batch. Each row has only one non-zero element\n",
    "            which is the TD-error corresponding to the action taken.\n",
    "        Returns:\n",
    "            The TD update (Array of dictionaries with gradient times TD errors) for the network's weights\n",
    "        \"\"\"\n",
    "\n",
    "        W0, b0 = self.weights[0]['W'], self.weights[0]['b']\n",
    "        W1, b1 = self.weights[1]['W'], self.weights[1]['b']\n",
    "\n",
    "        psi = np.dot(s, W0) + b0\n",
    "        x = np.maximum(psi, 0)\n",
    "        dx = (psi > 0).astype(float)\n",
    "\n",
    "        # td_update has the same structure as self.weights, that is an array of dictionaries.\n",
    "        # td_update[0][\"W\"], td_update[0][\"b\"], td_update[1][\"W\"], and td_update[1][\"b\"] have the same shape as\n",
    "        # self.weights[0][\"W\"], self.weights[0][\"b\"], self.weights[1][\"W\"], and self.weights[1][\"b\"] respectively\n",
    "        td_update = [dict() for i in range(len(self.weights))]\n",
    "\n",
    "        v = delta_mat\n",
    "        td_update[1]['W'] = np.dot(x.T, v) * 1. / s.shape[0]\n",
    "        td_update[1]['b'] = np.sum(v, axis=0, keepdims=True) * 1. / s.shape[0]\n",
    "\n",
    "        v = np.dot(v, W1.T) * dx\n",
    "        td_update[0]['W'] = np.dot(s.T, v) * 1. / s.shape[0]\n",
    "        td_update[0]['b'] = np.sum(v, axis=0, keepdims=True) * 1. / s.shape[0]\n",
    "\n",
    "        return td_update\n",
    "\n",
    "\n",
    "    def init_saxe(self, rows, cols):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            rows (int): number of input units for layer.\n",
    "            cols (int): number of output units for layer.\n",
    "        Returns:\n",
    "            NumPy Array consisting of weights for the layer based on the initialization in Saxe et al.\n",
    "        \"\"\"\n",
    "        tensor = self.rand_generator.normal(0, 1, (rows, cols))\n",
    "        if rows < cols:\n",
    "            tensor = tensor.T\n",
    "        tensor, r = np.linalg.qr(tensor)\n",
    "        d = np.diag(r, 0)\n",
    "        ph = np.sign(d)\n",
    "        tensor *= ph\n",
    "\n",
    "        if rows < cols:\n",
    "            tensor = tensor.T\n",
    "        return tensor\n",
    "\n",
    "\n",
    "    def get_weights(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            A copy of the current weights of this network.\n",
    "        \"\"\"\n",
    "        return deepcopy(self.weights)\n",
    "\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            weights (list of dictionaries): Consists of weights that this network will set as its own weights.\n",
    "        \"\"\"\n",
    "        self.weights = deepcopy(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b547f8",
   "metadata": {},
   "source": [
    "The Adam algorithm is an extension to stochastic gradient descent. It is a combination of two gradient descent methods, Momentum, and Root Mean Square Propagation (RMSP). It keeps running estimates of the mean and second moment of the updates, denoted by $\\mathbf{m}$ and $\\mathbf{v}$ respectively:\n",
    "$$\\mathbf{m_t} = \\beta_m \\mathbf{m_{t-1}} + (1 - \\beta_m)g_t \\\\\n",
    "\\mathbf{v_t} = \\beta_v \\mathbf{v_{t-1}} + (1 - \\beta_v)g^2_t\n",
    "$$\n",
    "\n",
    "Here, $\\beta_m$ and $\\beta_v$ are fixed parameters controlling the linear combinations above and $g_t$ is the update at time $t$ (generally the gradients, but here the TD error times the gradients).\n",
    "\n",
    "Given that $\\mathbf{m}$ and $\\mathbf{v}$ are initialized to zero, they are biased toward zero. To get unbiased estimates of the mean and second moment, Adam defines $\\mathbf{\\hat{m}}$ and $\\mathbf{\\hat{v}}$ as:\n",
    "$$ \\mathbf{\\hat{m}_t} = \\frac{\\mathbf{m_t}}{1 - \\beta_m^t} \\\\\n",
    "\\mathbf{\\hat{v}_t} = \\frac{\\mathbf{v_t}}{1 - \\beta_v^t}\n",
    "$$\n",
    "To calculate $\\mathbf{\\hat{m}}$ and $\\mathbf{\\hat{v}}$, we use powers of $\\beta_m$ and $\\beta_v$, respectively.\n",
    "The weights are then updated as follows:\n",
    "$$ \\mathbf{w_t} = \\mathbf{w_{t-1}} + \\frac{\\alpha}{\\sqrt{\\mathbf{\\hat{v}_t}}+\\epsilon} \\mathbf{\\hat{m}_t}\n",
    "$$\n",
    "\n",
    "Here, $\\alpha$ is the step size parameter and $\\epsilon$ is a small constant to keep the denominator from being zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "318d9b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam():\n",
    "    def __init__(self, layer_sizes,\n",
    "                 optimizer_info):\n",
    "        self.layer_sizes = layer_sizes\n",
    "\n",
    "        # Specify Adam algorithm's hyper parameters\n",
    "        self.step_size = optimizer_info.get(\"step_size\")\n",
    "        self.beta_m = optimizer_info.get(\"beta_m\")\n",
    "        self.beta_v = optimizer_info.get(\"beta_v\")\n",
    "        self.epsilon = optimizer_info.get(\"epsilon\")\n",
    "\n",
    "        # Initialize Adam algorithm's m and v\n",
    "        self.m = [dict() for i in range(1, len(self.layer_sizes))]\n",
    "        self.v = [dict() for i in range(1, len(self.layer_sizes))]\n",
    "\n",
    "        for i in range(0, len(self.layer_sizes) - 1):\n",
    "            # m and v are initialized to zero, with the same dimensions as the weights\n",
    "            self.m[i][\"W\"] = np.zeros((self.layer_sizes[i], self.layer_sizes[i + 1]))\n",
    "            self.m[i][\"b\"] = np.zeros((1, self.layer_sizes[i + 1]))\n",
    "            self.v[i][\"W\"] = np.zeros((self.layer_sizes[i], self.layer_sizes[i + 1]))\n",
    "            self.v[i][\"b\"] = np.zeros((1, self.layer_sizes[i + 1]))\n",
    "\n",
    "        self.beta_m_product = self.beta_m\n",
    "        self.beta_v_product = self.beta_v\n",
    "\n",
    "    def update_weights(self, weights, td_errors_times_gradients):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            weights (Array of dictionaries): The weights of the neural network.\n",
    "            td_errors_times_gradients (Array of dictionaries): The gradient of the\n",
    "            action-values with respect to the network's weights times the TD-error\n",
    "        Returns:\n",
    "            The updated weights (Array of dictionaries).\n",
    "        \"\"\"\n",
    "        for i in range(len(weights)):\n",
    "            for param in weights[i].keys():\n",
    "                # First, update m and v and then compute m_hat and v_hat. \n",
    "                # Then, compute how much the updated weights.\n",
    "                self.m[i][param] = self.beta_m * self.m[i][param] + \\\n",
    "                                (1 - self.beta_m) * td_errors_times_gradients[i][param]\n",
    "                self.v[i][param] = self.beta_v * self.v[i][param] + \\\n",
    "                                (1 - self.beta_v) * td_errors_times_gradients[i][param] ** 2\n",
    "                m_hat = self.m[i][param] / (1 - self.beta_m_product)\n",
    "                v_hat = self.v[i][param] / (1 - self.beta_v_product)\n",
    "                weight_update = (self.step_size / (np.sqrt(v_hat) + self.epsilon)) * m_hat\n",
    "                weights[i][param] = weights[i][param] + weight_update\n",
    "                \n",
    "        # To calculate m_hat and v_hat, we use powers of beta_m and beta_v\n",
    "        self.beta_m_product *= self.beta_m\n",
    "        self.beta_v_product *= self.beta_v\n",
    "\n",
    "        return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554fdfb7",
   "metadata": {},
   "source": [
    "The *optimize_network* function updates the action-value network weights using the defined optimizer. The update happens at an agent step using a sample batch of experiences from the replay buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c4d4eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(experiences, discount, optimizer, network, current_q, tau):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        experiences (Numpy array): The batch of experiences including the states, actions, \n",
    "                                   rewards, terminals, and next_states.\n",
    "        discount (float): The discount factor.\n",
    "        network (ActionValueNetwork): The latest state of the network that is getting replay updates.\n",
    "        current_q (ActionValueNetwork): The fixed network used for computing the targets, \n",
    "                                        and particularly, the action-values at the next-states.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get states, action, rewards, terminals, and next_states from experiences\n",
    "    states, actions, rewards, terminals, next_states = map(list, zip(*experiences))\n",
    "    states = np.concatenate(states)\n",
    "    next_states = np.concatenate(next_states)\n",
    "    rewards = np.array(rewards)\n",
    "    terminals = np.array(terminals)\n",
    "    batch_size = states.shape[0]\n",
    "\n",
    "    # Compute TD error using the get_td_error function\n",
    "    # Note that delta_vec is a 1D array of shape (batch_size)\n",
    "    delta_vec = get_td_error(states, next_states, actions, rewards, discount, terminals, network, current_q, tau)\n",
    "\n",
    "    # Batch Indices is an array from 0 to the batch_size - 1. \n",
    "    batch_indices = np.arange(batch_size)\n",
    "\n",
    "    # Make a td error matrix of shape (batch_size, num_actions)\n",
    "    # delta_mat has non-zero value only for actions taken\n",
    "    delta_mat = np.zeros((batch_size, network.num_actions))\n",
    "    delta_mat[batch_indices, actions] = delta_vec\n",
    "\n",
    "    # Pass delta_mat to compute the TD errors times the gradients of the network's weights from back-propagation\n",
    "    td_update = network.get_TD_update(states, delta_mat)    \n",
    "    \n",
    "    # Pass network.get_weights and the td_update to the optimizer to get updated weights\n",
    "    weights = optimizer.update_weights(network.get_weights(), td_update)\n",
    "    \n",
    "    # Update network weights\n",
    "    network.set_weights(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2fa7f",
   "metadata": {},
   "source": [
    "The TD error is necessary for the network weight update for the action-value function represented as a neural network, $Q_t$. The update is done using Expected SARSA:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\text{Expected Sarsa update : } Q_{t+1}^{i+1}(s, a) \\leftarrow Q_{t+1}^{i}(s, a) + \\alpha \\cdot \\left[r + \\gamma \\left(\\sum_{b} \\pi(b | s') Q_t(s', b)\\right) - Q_{t+1}^{i}(s, a)\\right] \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The term $\\gamma \\left(\\sum_{b} \\pi(b | s') Q_t(s', b)\\right)$ is active for non-terminal transitions only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18ccd8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_td_error(states, next_states, actions, rewards, discount, terminals, network, current_q, tau):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        states (Numpy array): The batch of states with the shape (batch_size, state_dim).\n",
    "        next_states (Numpy array): The batch of next states with the shape (batch_size, state_dim).\n",
    "        actions (Numpy array): The batch of actions with the shape (batch_size,).\n",
    "        rewards (Numpy array): The batch of rewards with the shape (batch_size,).\n",
    "        discount (float): The discount factor.\n",
    "        terminals (Numpy array): The batch of terminals with the shape (batch_size,).\n",
    "        network (ActionValueNetwork): The latest state of the network that is getting replay updates.\n",
    "        current_q (ActionValueNetwork): The fixed network used for computing the targets, \n",
    "                                        and particularly, the action-values at the next-states.\n",
    "    Returns:\n",
    "        The TD errors (Numpy array) for actions taken, of shape (batch_size,)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Note: Here network is the latest state of the network that is getting replay updates. In other words, \n",
    "    # the network represents Q_{t+1}^{i} whereas current_q represents Q_t, the fixed network used for computing the \n",
    "    # targets, and particularly, the action-values at the next-states.\n",
    "    \n",
    "    # Compute action values at next states using current_q network\n",
    "    # q_next_mat is a 2D array of shape (batch_size, num_actions)\n",
    "    q_next_mat = current_q.get_action_values(next_states)    \n",
    "    \n",
    "    # Compute policy at next state by passing the action-values in q_next_mat to softmax()\n",
    "    # probs_mat is a 2D array of shape (batch_size, num_actions)\n",
    "    probs_mat = softmax(q_next_mat, tau)\n",
    "    \n",
    "    # Compute the estimate of the next state value, v_next_vec.\n",
    "    # Expected SARSA: sum the action-values for the next_states weighted by the policy, probs_mat. Then, multiply by\n",
    "    # (1 - terminals) to make sure v_next_vec is zero for terminal next states.\n",
    "    # v_next_vec is a 1D array of shape (batch_size,)\n",
    "    v_next_vec = np.sum(q_next_mat * probs_mat, axis=1)\n",
    "    v_next_vec = v_next_vec * ( 1- terminals)\n",
    "    \n",
    "    # Compute Expected SARSA target\n",
    "    # target_vec is a 1D array of shape (batch_size,)\n",
    "    target_vec = rewards + discount * v_next_vec\n",
    "    \n",
    "    # Compute action values at the current states for all actions using network\n",
    "    # q_mat is a 2D array of shape (batch_size, num_actions)\n",
    "    q_mat = network.get_action_values(states)\n",
    "    \n",
    "    # Batch Indices is an array from 0 to the batch size - 1. \n",
    "    batch_indices = np.arange(q_mat.shape[0])\n",
    "\n",
    "    # Compute q_vec by selecting q(s, a) from q_mat for taken actions\n",
    "    # Use batch_indices as the index for the first dimension of q_mat\n",
    "    # q_vec is a 1D array of shape (batch_size)\n",
    "    q_vec = q_mat[batch_indices, actions]\n",
    "    \n",
    "    # Compute TD errors for actions taken\n",
    "    # delta_vec is a 1D array of shape (batch_size)\n",
    "    delta_vec = target_vec - q_vec\n",
    "    \n",
    "    return delta_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e655dca",
   "metadata": {},
   "source": [
    "The policy at the next state is computed by passing the action-values to the following *softmax()* function, which calculates the probability distribution over the actions representing the policy. The softmax policy explores according to the action-values, meaning that an action with a moderate value has a higher chance of getting selected compared to an action with a lower value. In contrast, an $\\epsilon-$greedy policy does not consider the individual action values and chooses randomly:\n",
    "\n",
    "$$Pr{(A_t=a | S_t=s)} \\hspace{0.1cm} \\dot{=} \\hspace{0.1cm} \\frac{e^{Q(s, a)/\\tau - max_{c}Q(s, c)/\\tau}}{\\sum_{b \\in A}e^{Q(s, b)/\\tau - max_{c}Q(s, c)/\\tau}}$$\n",
    "\n",
    "The parameter $\\tau$ is the temperature parameter which controls how much the agent focuses on the highest valued actions. For smaller values of $\\tau$, the agent selects more greedily from the higher action values. For large values of $\\tau$, the agent selects among actions more uniformly at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8442446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(action_values, tau=1.0):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        action_values (Numpy array): A 2D array of shape (batch_size, num_actions). \n",
    "                       The action-values computed by an action-value network.              \n",
    "        tau (float): The temperature parameter scalar.\n",
    "    Returns:\n",
    "        A 2D array of shape (batch_size, num_actions). Where each column is a probability distribution over\n",
    "        the actions representing the policy.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute the preferences by dividing the action-values by the temperature parameter tau\n",
    "    preferences =  action_values / tau\n",
    "    # Compute the maximum preference across the actions\n",
    "    max_preference = np.max(preferences, axis = 1) \n",
    "    \n",
    "    \n",
    "    # Reshape max_preference array which has shape [Batch,] to [Batch, 1]. This allows NumPy broadcasting \n",
    "    # when subtracting the maximum preference from the preference of each action.\n",
    "    reshaped_max_preference = max_preference.reshape((-1, 1))\n",
    "    \n",
    "    # Compute the exponential of the preference - the max preference.\n",
    "    exp_preferences = np.exp(preferences - reshaped_max_preference)    \n",
    "    # Compute the sum over exp_preferences along the actions axis.\n",
    "    sum_of_exp_preferences = np.sum(exp_preferences, axis = 1)\n",
    "    \n",
    "    # Reshape sum_of_exp_preferences array which has shape [Batch,] to [Batch, 1] to  allow for NumPy broadcasting \n",
    "    # when dividing the numerator by the denominator.\n",
    "    reshaped_sum_of_exp_preferences = sum_of_exp_preferences.reshape((-1, 1))\n",
    "    \n",
    "    # Compute the action probabilities\n",
    "    action_probs = exp_preferences / reshaped_sum_of_exp_preferences\n",
    "    \n",
    "    \n",
    "    # squeeze() removes any singleton dimensions. It is used here because this function is used in the \n",
    "    # agent policy when selecting an action (for which the batch dimension is 1.) As np.random.choice is used in \n",
    "    # the agent policy and it expects 1D arrays, we need to remove this singleton batch dimension.\n",
    "    action_probs = action_probs.squeeze()\n",
    "    return action_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714daf1",
   "metadata": {},
   "source": [
    "# 3. Define Environment\n",
    "Create abstract environment class to implement an RL-Glue environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed7bf6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Abstract environment base class for RL-Glue-py.\n",
    "\"\"\"\n",
    "class BaseEnvironment(ABC):\n",
    "    \"\"\"Implements the environment for an RLGlue environment\n",
    "\n",
    "    Note:\n",
    "        env_init, env_start, env_step, env_cleanup, and env_message are required\n",
    "        methods.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        reward = None\n",
    "        observation = None\n",
    "        termination = None\n",
    "        self.reward_obs_term = (reward, observation, termination)\n",
    "\n",
    "    @abstractmethod\n",
    "    def env_init(self, env_info={}):\n",
    "        \"\"\"Setup for the environment called when the experiment first starts.\n",
    "\n",
    "        Note:\n",
    "            Initialize a tuple with the reward, first state observation, boolean\n",
    "            indicating if it's terminal.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def env_start(self):\n",
    "        \"\"\"The first method called when the experiment starts, called before the\n",
    "        agent starts.\n",
    "\n",
    "        Returns:\n",
    "            The first state observation from the environment.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def env_step(self, action):\n",
    "        \"\"\"A step taken by the environment.\n",
    "\n",
    "        Args:\n",
    "            action: The action taken by the agent\n",
    "\n",
    "        Returns:\n",
    "            (float, state, Boolean): a tuple of the reward, state observation,\n",
    "                and boolean indicating if it's terminal.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def env_cleanup(self):\n",
    "        \"\"\"Cleanup done after the environment ends\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def env_message(self, message):\n",
    "        \"\"\"A message asking the environment for information\n",
    "\n",
    "        Args:\n",
    "            message: the message passed to the environment\n",
    "\n",
    "        Returns:\n",
    "            the response (or answer) to the message\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7acc89e",
   "metadata": {},
   "source": [
    "Create the **Lunar Lander** environment using box2d from **gymnasium**. The environment provides the agent with a reward after every step, based on its action and state. The total reward of an episode is the sum of the rewards for all the steps within that episode.\n",
    "\n",
    "For each step, the reward:\n",
    "- is increased/decreased the closer/further the lander is to the landing pad.\n",
    "- is increased/decreased the slower/faster the lander is moving.\n",
    "- is decreased the more the lander is tilted (angle not horizontal).\n",
    "- is increased by 10 points for each leg that is in contact with the ground.\n",
    "- is decreased by 0.03 points each frame a side engine is firing.\n",
    "- is decreased by 0.3 points each frame the main engine is firing.\n",
    "\n",
    "The episode receive an additional reward of -100 or +100 points for crashing or landing safely respectively.\n",
    "\n",
    "An episode is considered a solution if it scores at least 200 points.\n",
    "\n",
    "The episode finishes if:\n",
    "- the lander crashes (the lander body gets in contact with the moon);\n",
    "- the lander gets outside of the viewport;\n",
    "- the lander is not awake. A body which is not awake is a body which doesn't move and doesn't collide with any other body.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc914de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LunarLanderEnvironment(BaseEnvironment):\n",
    "    def env_init(self, env_info={}):\n",
    "        \"\"\"\n",
    "        Setup for the environment called when the experiment first starts.\n",
    "        \"\"\"\n",
    "        self.render_mode = env_info[\"render_mode\"]\n",
    "        self.env = gym.make(\"LunarLander-v2\", render_mode = self.render_mode)\n",
    "\n",
    "    def env_start(self):\n",
    "        \"\"\"\n",
    "        The first method called when the experiment starts, called before the\n",
    "        agent starts.\n",
    "\n",
    "        Returns:\n",
    "            The first state observation from the environment.\n",
    "        \"\"\"\n",
    "\n",
    "        reward = 0.0\n",
    "        observation = self.env.reset()\n",
    "        is_terminal = False\n",
    "\n",
    "        self.reward_obs_term = (reward, observation, is_terminal)\n",
    "\n",
    "        # return first state observation from the environment\n",
    "        return self.reward_obs_term[1][0]\n",
    "\n",
    "    def env_step(self, action):\n",
    "        \"\"\"A step taken by the environment.\n",
    "\n",
    "        Args:\n",
    "            action: The action taken by the agent\n",
    "\n",
    "        Returns:\n",
    "            (float, state, Boolean): a tuple of the reward, state observation,\n",
    "                and boolean indicating if it's terminal.\n",
    "        \"\"\"\n",
    "\n",
    "        last_state = self.reward_obs_term[1]\n",
    "        current_state, reward, is_terminal, _, _ = self.env.step(action)\n",
    "\n",
    "        self.reward_obs_term = (reward, current_state, is_terminal)\n",
    "\n",
    "        return self.reward_obs_term\n",
    "    \n",
    "    def env_cleanup(self):\n",
    "        \"\"\"Cleanup done after the environment ends\"\"\"\n",
    "\n",
    "    def env_message(self, message):\n",
    "        \"\"\"A message asking the environment for information\n",
    "\n",
    "        Args:\n",
    "            message: the message passed to the environment\n",
    "\n",
    "        Returns:\n",
    "            the response (or answer) to the message\n",
    "        \"\"\"        \n",
    "        if message == \"get_sum_reward\":\n",
    "            return self.sum_rewards\n",
    "        else:\n",
    "            raise Exception(\"Unrecognized Message!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a98cb9",
   "metadata": {},
   "source": [
    "# 4. Define Experiment\n",
    "The RLGlue class puts an agent in an environment and to perform reinforcement learning experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec60fe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Glues together an experiment, agent, and environment.\n",
    "\"\"\"\n",
    "\n",
    "class RLGlue:\n",
    "    \"\"\"RLGlue class\n",
    "\n",
    "    args:\n",
    "        env_name (string): the name of the module where the Environment class can be found\n",
    "        agent_name (string): the name of the module where the Agent class can be found\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env_class, agent_class):\n",
    "        self.environment = env_class()\n",
    "        self.agent = agent_class()\n",
    "\n",
    "        self.total_reward = None\n",
    "        self.last_action = None\n",
    "        self.num_steps = None\n",
    "        self.num_episodes = None\n",
    "\n",
    "    def rl_init(self, agent_init_info={}, env_init_info={}):\n",
    "        \"\"\"Initial method called when RLGlue experiment is created\"\"\"\n",
    "        self.environment.env_init(env_init_info)\n",
    "        self.agent.agent_init(agent_init_info)\n",
    "\n",
    "        self.total_reward = 0.0\n",
    "        self.num_steps = 0\n",
    "        self.num_episodes = 0\n",
    "\n",
    "    def rl_start(self, agent_start_info={}, env_start_info={}):\n",
    "        \"\"\"Starts RLGlue experiment\n",
    "\n",
    "        Returns:\n",
    "            tuple: (state, action)\n",
    "        \"\"\"\n",
    "\n",
    "        self.total_reward = 0.0\n",
    "        self.num_steps = 1\n",
    "\n",
    "        last_state = self.environment.env_start()\n",
    "        self.last_action = self.agent.agent_start(last_state)\n",
    "\n",
    "        observation = (last_state, self.last_action)\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def rl_agent_start(self, observation):\n",
    "        \"\"\"Starts the agent.\n",
    "\n",
    "        Args:\n",
    "            observation: The first observation from the environment\n",
    "\n",
    "        Returns:\n",
    "            The action taken by the agent.\n",
    "        \"\"\"\n",
    "        return self.agent.agent_start(observation)\n",
    "\n",
    "    def rl_agent_step(self, reward, observation):\n",
    "        \"\"\"Step taken by the agent\n",
    "\n",
    "        Args:\n",
    "            reward (float): the last reward the agent received for taking the\n",
    "                last action.\n",
    "            observation : the state observation the agent receives from the\n",
    "                environment.\n",
    "\n",
    "        Returns:\n",
    "            The action taken by the agent.\n",
    "        \"\"\"\n",
    "        return self.agent.agent_step(reward, observation)\n",
    "\n",
    "    def rl_agent_end(self, reward):\n",
    "        \"\"\"Run when the agent terminates\n",
    "\n",
    "        Args:\n",
    "            reward (float): the reward the agent received when terminating\n",
    "        \"\"\"\n",
    "        self.agent.agent_end(reward)\n",
    "\n",
    "    def rl_env_start(self):\n",
    "        \"\"\"Starts RL-Glue environment.\n",
    "\n",
    "        Returns:\n",
    "            (float, state, Boolean): reward, state observation, boolean\n",
    "                indicating termination\n",
    "        \"\"\"\n",
    "        self.total_reward = 0.0\n",
    "        self.num_steps = 1\n",
    "\n",
    "        this_observation = self.environment.env_start()\n",
    "\n",
    "        return this_observation\n",
    "\n",
    "    def rl_env_step(self, action):\n",
    "        \"\"\"Step taken by the environment based on action from agent\n",
    "\n",
    "        Args:\n",
    "            action: Action taken by agent.\n",
    "\n",
    "        Returns:\n",
    "            (float, state, Boolean): reward, state observation, boolean\n",
    "                indicating termination.\n",
    "        \"\"\"\n",
    "        ro = self.environment.env_step(action)\n",
    "        (this_reward, _, terminal) = ro\n",
    "\n",
    "        self.total_reward += this_reward\n",
    "\n",
    "        if terminal:\n",
    "            self.num_episodes += 1\n",
    "        else:\n",
    "            self.num_steps += 1\n",
    "\n",
    "        return ro\n",
    "\n",
    "    def rl_step(self):\n",
    "        \"\"\"Step taken by RLGlue, takes environment step and either step or\n",
    "            end by agent.\n",
    "\n",
    "        Returns:\n",
    "            (float, state, action, Boolean): reward, last state observation,\n",
    "                last action, boolean indicating termination\n",
    "        \"\"\"\n",
    "\n",
    "        (reward, last_state, term) = self.environment.env_step(self.last_action)\n",
    "\n",
    "        self.total_reward += reward;\n",
    "\n",
    "        if term:\n",
    "            self.num_episodes += 1\n",
    "            self.agent.agent_end(reward)\n",
    "            roat = (reward, last_state, None, term)\n",
    "        else:\n",
    "            self.num_steps += 1\n",
    "            self.last_action = self.agent.agent_step(reward, last_state)\n",
    "            roat = (reward, last_state, self.last_action, term)\n",
    "\n",
    "        return roat\n",
    "\n",
    "    def rl_cleanup(self):\n",
    "        \"\"\"Cleanup done at end of experiment.\"\"\"\n",
    "        self.environment.env_cleanup()\n",
    "        self.agent.agent_cleanup()\n",
    "\n",
    "    def rl_agent_message(self, message):\n",
    "        \"\"\"Message passed to communicate with agent during experiment\n",
    "\n",
    "        Args:\n",
    "            message: the message (or question) to send to the agent\n",
    "\n",
    "        Returns:\n",
    "            The message back (or answer) from the agent\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        return self.agent.agent_message(message)\n",
    "\n",
    "    def rl_env_message(self, message):\n",
    "        \"\"\"Message passed to communicate with environment during experiment\n",
    "\n",
    "        Args:\n",
    "            message: the message (or question) to send to the environment\n",
    "\n",
    "        Returns:\n",
    "            The message back (or answer) from the environment\n",
    "\n",
    "        \"\"\"\n",
    "        return self.environment.env_message(message)\n",
    "\n",
    "    def rl_episode(self, max_steps_this_episode):\n",
    "        \"\"\"Runs an RLGlue episode\n",
    "\n",
    "        Args:\n",
    "            max_steps_this_episode (Int): the maximum steps for the experiment to run in an episode\n",
    "\n",
    "        Returns:\n",
    "            Boolean: if the episode should terminate\n",
    "        \"\"\"\n",
    "        is_terminal = False\n",
    "\n",
    "        self.rl_start()\n",
    "\n",
    "        while (not is_terminal) and ((max_steps_this_episode == 0) or\n",
    "                                     (self.num_steps < max_steps_this_episode)):\n",
    "            rl_step_result = self.rl_step()\n",
    "            is_terminal = rl_step_result[3]\n",
    "\n",
    "        return is_terminal\n",
    "\n",
    "    def rl_return(self):\n",
    "        \"\"\"The total reward\n",
    "\n",
    "        Returns:\n",
    "            float: the total reward\n",
    "        \"\"\"\n",
    "        return self.total_reward\n",
    "\n",
    "    def rl_num_steps(self):\n",
    "        \"\"\"The total number of steps taken\n",
    "\n",
    "        Returns:\n",
    "            Int: the total number of steps taken\n",
    "        \"\"\"\n",
    "        return self.num_steps\n",
    "\n",
    "    def rl_num_episodes(self):\n",
    "        \"\"\"The number of episodes\n",
    "\n",
    "        Returns\n",
    "            Int: the total number of episodes\n",
    "\n",
    "        \"\"\"\n",
    "        return self.num_episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dad1a0",
   "metadata": {},
   "source": [
    "The *run_experiment* function puts together agent, environment and experiment parameters and initiates the experiment. It stores the experiment rewards in a *results* folder. A progress bar shows the current episode number during an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11209b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(rl_glue, environment_parameters, agent_parameters, experiment_parameters):\n",
    "    \n",
    "    # save sum of reward at the end of each episode\n",
    "    agent_sum_reward = np.zeros((experiment_parameters[\"num_runs\"],\n",
    "                                 experiment_parameters[\"num_episodes\"]))\n",
    "\n",
    "    env_info = environment_parameters\n",
    "\n",
    "    agent_info = agent_parameters\n",
    "\n",
    "    # one agent setting\n",
    "    for run in range(1, experiment_parameters[\"num_runs\"] + 1):\n",
    "        agent_info[\"seed\"] = run\n",
    "        agent_info[\"network_config\"][\"seed\"] = run\n",
    "        env_info[\"seed\"] = run\n",
    "\n",
    "        rl_glue.rl_init(agent_info, env_info)\n",
    "\n",
    "        for episode in tqdm(range(1, experiment_parameters[\"num_episodes\"] + 1)):\n",
    "            # run episode\n",
    "            rl_glue.rl_episode(experiment_parameters[\"timeout\"])\n",
    "\n",
    "            episode_reward = rl_glue.rl_agent_message(\"get_sum_reward\")\n",
    "            agent_sum_reward[run - 1, episode - 1] = episode_reward\n",
    "    save_name = \"{}\".format(rl_glue.agent.name)\n",
    "    if not os.path.exists('results'):\n",
    "        os.makedirs('results')\n",
    "        \n",
    "    np.save(\"results/sum_reward_{}\".format(save_name), agent_sum_reward)\n",
    "    shutil.make_archive('results', 'zip', 'results')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92264c6",
   "metadata": {},
   "source": [
    "# 5. Run experiment\n",
    "The functions *smooth* and *plot_result* are used to plot the smoothed total rewards from the agent training, as stored in the *results* folder at the end of each experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82191048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(data, k):\n",
    "    num_episodes = data.shape[1]\n",
    "    num_runs = data.shape[0]\n",
    "\n",
    "    smoothed_data = np.zeros((num_runs, num_episodes))\n",
    "\n",
    "    for i in range(num_episodes):\n",
    "        if i < k:\n",
    "            smoothed_data[:, i] = np.mean(data[:, :i + 1], axis=1)\n",
    "        else:\n",
    "            smoothed_data[:, i] = np.mean(data[:, i - k:i + 1], axis=1)\n",
    "\n",
    "    return smoothed_data\n",
    "\n",
    "# Function to plot result\n",
    "def plot_result(data_name_array):\n",
    "    plt_agent_sweeps = []\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    for data_name in data_name_array:\n",
    "        # load data\n",
    "        filename = 'sum_reward_{}'.format(data_name).replace('.', '')\n",
    "        sum_reward_data = np.load('{}/{}.npy'.format(path_dict[data_name], filename))\n",
    "        \n",
    "        # smooth data\n",
    "        smoothed_sum_reward = smooth(data=sum_reward_data, k=100)\n",
    "\n",
    "        mean_smoothed_sum_reward = np.mean(smoothed_sum_reward, axis=0)\n",
    "        \n",
    "        plot_x_range = np.arange(0, mean_smoothed_sum_reward.shape[0])\n",
    "        graph_current_agent_sum_reward, = ax.plot(plot_x_range, mean_smoothed_sum_reward[:],\n",
    "                                                      label=plt_legend_dict[data_name])\n",
    "        plt_agent_sweeps.append(graph_current_agent_sum_reward)\n",
    "\n",
    "    ax.legend(handles=plt_agent_sweeps, fontsize=13)\n",
    "    ax.set_title(\"Learning Curve\", fontsize=15)\n",
    "    ax.set_xlabel('Episodes', fontsize=14)\n",
    "    ax.set_ylabel(plt_label_dict[data_name_array[0]], rotation=0, labelpad=40, fontsize=14)\n",
    "    ax.set_ylim([-300, 300])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531662ed",
   "metadata": {},
   "source": [
    "Define the experiment, environment, and agent parameters for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d64aa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 300/300 [04:22<00:00,  1.14it/s]\n",
      "100%|| 300/300 [04:15<00:00,  1.18it/s]\n",
      "100%|| 300/300 [04:35<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Starting!\")\n",
    "# Run Experiment\n",
    "\n",
    "# Experiment parameters\n",
    "experiment_parameters = {\n",
    "    \"num_runs\": 3,\n",
    "    \"num_episodes\": 300,\n",
    "    # OpenAI Gym environments allow for a timestep limit timeout, causing episodes to end after\n",
    "    # some number of timesteps. Here we use the default of 500.\n",
    "    \"timeout\": 500\n",
    "}\n",
    "\n",
    "# Environment parameters\n",
    "environment_parameters = {\n",
    "    \"render_mode\" : 'rgb_array'}\n",
    "\n",
    "current_env = LunarLanderEnvironment\n",
    "\n",
    "# Agent parameters\n",
    "agent_parameters = {\n",
    "    'agent_name' : 'test',\n",
    "    'network_config': {\n",
    "        'state_dim': 8,\n",
    "        'num_hidden_units': 256,\n",
    "        'num_actions': 4\n",
    "    },\n",
    "    'optimizer_config': {\n",
    "        'step_size': 1e-3,\n",
    "        'beta_m': 0.9,\n",
    "        'beta_v': 0.999,\n",
    "        'epsilon': 1e-8\n",
    "    },\n",
    "    'replay_buffer_size': 50000,\n",
    "    'minibatch_sz': 8,\n",
    "    'num_replay_updates_per_step': 4,\n",
    "    'gamma': 0.99,\n",
    "    'tau': 0.001\n",
    "}\n",
    "current_agent = ExperienceReplay_Agent\n",
    "\n",
    "# run experiment\n",
    "rl_glue = RLGlue(current_env, current_agent)\n",
    "run_experiment(rl_glue, environment_parameters, agent_parameters, experiment_parameters)\n",
    "\n",
    "# save trained agent\n",
    "joblib.dump(rl_glue.agent, \"agent.pickle\")\n",
    "\n",
    "print(\"Finished!\")\n",
    "    \n",
    "\n",
    "\n",
    "plt_legend_dict = {\"expected_sarsa_agent_test\": \"Expected SARSA with neural network\",\n",
    "                   \"random_agent\": \"Random\"}\n",
    "path_dict = {\"expected_sarsa_agent_test\": \"results/\",\n",
    "             \"random_agent\": \"./\"}\n",
    "plt_label_dict = {\"expected_sarsa_agent_test\": \"Sum of\\nreward\\nduring\\nepisode\"}\n",
    "\n",
    "plot_result([\"expected_sarsa_agent_test\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9331d43",
   "metadata": {},
   "source": [
    "# Get the environment to run with the trained agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ceaf145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment\n",
    "environment_parameters = {\n",
    "    \"render_mode\" : 'human'}\n",
    "env = LunarLanderEnvironment()\n",
    "env.env_init(environment_parameters)\n",
    "\n",
    "# Load agent\n",
    "rl_glue.agent = joblib.load(\"agent.pickle\") \n",
    "rl_glue.agent.num_replay = 0\n",
    "rl_glue.agent.tau = 0.001\n",
    "\n",
    "# Initialize environment\n",
    "observation = env.env_start()\n",
    "state = observation\n",
    "reward = 0\n",
    "terminal = False\n",
    "max_steps_this_episode = 500\n",
    "num_steps = 0\n",
    "\n",
    "while (not terminal) and ((max_steps_this_episode == 0) or\n",
    "                                     (num_steps < max_steps_this_episode)):\n",
    "    action = rl_glue.rl_agent_step(reward, state)  \n",
    "    reward, new_state, terminal = env.env_step(action)\n",
    "    state = new_state\n",
    "    num_steps += 1\n"
   ]
  },
  {
   "attachments": {
    "lunarLanding.jpg": {
     "image/jpeg": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c7f279ac",
   "metadata": {},
   "source": [
    "![lunarLanding.jpg](attachment:lunarLanding.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cebad54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
